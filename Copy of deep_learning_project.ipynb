{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of deep_learning_project.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"v7hi-HFFUEBD","colab_type":"code","outputId":"ba826755-24bb-47e4-c733-6b76237c4686","executionInfo":{"status":"ok","timestamp":1579000559687,"user_tz":0,"elapsed":21736,"user":{"displayName":"Will Leeney","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD-9CtGsg_Lu6ZnMvRSZ00NwTBxu8ocBiKBqmrJ5G0=s64","userId":"12065771172714949840"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["### CODE TO ACCESS DRIVE ###\n","# Run\n","# Follow Link\n","# Copy Link, Paste and Enter \n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XsL7HM-rUIod","colab_type":"code","outputId":"d39eac4b-6623-4f0a-dbf6-6b1339090990","executionInfo":{"status":"ok","timestamp":1579000564210,"user_tz":0,"elapsed":601,"user":{"displayName":"Will Leeney","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD-9CtGsg_Lu6ZnMvRSZ00NwTBxu8ocBiKBqmrJ5G0=s64","userId":"12065771172714949840"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Change to Drive folder - might be different path\n","%cd /content/drive/My Drive/'Colab Notebooks'/\n","#%cd /content/drive/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wuU50PPAU-3k","colab_type":"code","outputId":"d0403239-09b5-45a4-fbf3-c34ab2b8c1f7","executionInfo":{"status":"ok","timestamp":1579000569457,"user_tz":0,"elapsed":1943,"user":{"displayName":"Will Leeney","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD-9CtGsg_Lu6ZnMvRSZ00NwTBxu8ocBiKBqmrJ5G0=s64","userId":"12065771172714949840"}},"colab":{"base_uri":"https://localhost:8080/","height":187}},"source":["# Check in correct folder \n","%ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":[" checkpoint.pkl                             \u001b[0m\u001b[01;34mlogs\u001b[0m/\n","'Copy of deep_learning_project (1).ipynb'   MCcheckpoint.pkl\n","'Copy of deep_learning_project.ipynb'       MC_scores.p\n"," dataset1.py                                MLMCcheckpoint.pkl\n"," dataset.py                                 MLMC_scores.p\n"," deep_learning_project.ipynb                \u001b[01;34mpictures\u001b[0m/\n"," Lab4.ipynb                                 \u001b[01;34m__pycache__\u001b[0m/\n"," labels.p                                   UrbanSound8K_test.pkl\n"," LMCcheckpoint.pkl                          UrbanSound8K_train.pkl\n"," LMC_scores.p\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"f53aa2a5-b69e-4615-d2bd-a8ffe3d4a4db","executionInfo":{"status":"ok","timestamp":1579018321616,"user_tz":0,"elapsed":2484,"user":{"displayName":"Will Leeney","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD-9CtGsg_Lu6ZnMvRSZ00NwTBxu8ocBiKBqmrJ5G0=s64","userId":"12065771172714949840"}},"id":"GSPEiq6OzKb9","cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":578}},"source":["## Libraries\n","import time\n","from multiprocessing import cpu_count\n","from typing import Union, NamedTuple\n","\n","import torch\n","import torch.backends.cudnn\n","import numpy as np\n","from torch import nn, optim\n","from torch.nn import functional as F\n","import torchvision.datasets\n","from torch.optim.optimizer import Optimizer\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision import transforms\n","\n","import argparse\n","import os\n","from pathlib import Path\n","\n","from torch.utils import data\n","from dataset import UrbanSound8KDataset\n","import random\n","import pickle \n","\n","torch.backends.cudnn.benchmark = True\n","parser = argparse.ArgumentParser(\n","                        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n","                        )\n","## Arguments\n","default_dataset_dir = Path.home() / \".cache\" / \"torch\" / \"datasets\"\n","parser.add_argument(\"--log-dir\", default=Path(\"logsold\"), type=Path)\n","parser.add_argument(\"--dataset-root\", default=default_dataset_dir)\n","parser.add_argument(\"--learning_rate\",default = 1e-3, type=float, help=\"Learning rate\")\n","parser.add_argument(\"--sgd_momentum\",default =  0.9, type=float)\n","parser.add_argument(\"--dropout\", default = 0.5, type = float)\n","parser.add_argument(\"--score_calc\", default = True, type = bool, help =\"whether to print out currrent scores of models\")\n","parser.add_argument(\"--mode\", default = 'TSCNN', type = str, help=\"Mode of network to train. Run both LMC and MC before TSCNN. Options: LMC, MC, MLMC, TSCNN, SCORES\")\n","parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","parser.add_argument(\n","    \"--batch-size\",\n","    default=32,\n","    type=int,\n","    help=\"Number of images within each mini-batch\",\n",")\n","parser.add_argument(\n","    \"--epochs\",\n","    default=31,\n","    type=int,\n","    help=\"Number of epochs (passes through the entire dataset) to train for\",\n",")\n","parser.add_argument(\n","    \"--val-frequency\",\n","    default=1,\n","    type=int,\n","    help=\"How frequently to test the model on the validation set in number of epochs\",\n","    )\n","parser.add_argument(\n","    \"--log-frequency\",\n","    default=10,\n","    type=int,\n","    help=\"How frequently to save logs to tensorboard in number of steps\",\n",")\n","parser.add_argument(\n","    \"--print-frequency\",\n","    default=100,\n","    type=int,\n","    help=\"How frequently to print progress to the command line in number of steps\",\n",")\n","parser.add_argument(\n","    \"-j\",\n","    \"--worker-count\",\n","    default=cpu_count(),\n","    type=int,\n","    help=\"Number of worker processes used to load data.\",\n",")\n","parser.add_argument(\n","    \"--checkpoint-path\",\n","    default=\"checkpointold.pkl\",\n","    type=str,\n","    help=\"Provide a file to store checkpoints of the model parameters during training.\"\n",")\n","parser.add_argument(\n","    \"--weight_decay\",\n","    default=1e-5,\n","    type=float,\n","    help=\"Weight decay: parameter related to L-2 regularisation.\",\n",")\n","\n","class ImageShape(NamedTuple):\n","    height: int\n","    width: int\n","    channels: int\n","\n","if torch.cuda.is_available():\n","    DEVICE = torch.device(\"cuda\")\n","else:\n","    DEVICE = torch.device(\"cpu\")\n","\n","def main(args):\n","    args.dataset_root.mkdir(parents=True, exist_ok=True)\n","\n","    ## specifiy checkpoint path\n","    mode = args.mode\n","    checkpoint_path = args.checkpoint_path\n","    checkpoint_path = Path(mode + checkpoint_path)\n","\n","    if args.score_calc == True: \n","        modes = ['LMC', 'MC', 'MLMC']\n","        class_labels = [\"ac\", \"ch\", \"cp\", \"db\", \"dr\", \"ei\", \"gs\", \"jh\", \"si\", \"sm\"]\n","        labels = pickle.load(open('labels.p', 'rb'))\n","        # load saved scores\n","        for i in modes: \n","            scores = pickle.load(open(f\"{i}_scores.p\", \"rb\"))\n","            preds = scores.argmax(dim=-1).cpu().numpy()\n","            accuracy, per_class_accuracy = compute_accuracy(\n","                np.array(preds), np.array(labels)\n","            )\n","            print(f\"{i}_accuracy: {accuracy * 100:2.1f}\")\n","            for j in range(0,10):\n","                print(f\"{class_labels[j]}_acc: {per_class_accuracy[j] * 100:2.1f}\")\n","\n","    elif mode == 'TSCNN':\n","        LMC_scores = pickle.load(open('LMC_scores.p', 'rb'))\n","        MC_scores = pickle.load(open('MC_scores.p', 'rb'))\n","        labels = pickle.load(open('labels.p', 'rb'))\n","\n","        scores = LMC_scores + MC_scores\n","        \n","        preds = scores.argmax(dim=-1).cpu().numpy()\n","        accuracy, per_class_accuracy = compute_accuracy(\n","              np.array(preds), np.array(labels)\n","          )\n","        class_labels = [\"ac\", \"ch\", \"cp\", \"db\", \"dr\", \"ei\", \"gs\", \"jh\", \"si\", \"sm\"]\n","        print(f\"accuracy: {accuracy * 100:2.1f}\")\n","        for i in range(0,10):\n","            print(f\"{class_labels[i]}_acc: {per_class_accuracy[i] * 100:2.1f}\")\n","\n","    else: \n","        ## load data\n","        train_loader = torch.utils.data.DataLoader(\n","            UrbanSound8KDataset('UrbanSound8K_train.pkl', mode),\n","              batch_size=args.batch_size, shuffle=True,\n","              num_workers=args.worker_count, pin_memory=True\n","              )\n","\n","        val_loader = torch.utils.data.DataLoader(\n","            UrbanSound8KDataset('UrbanSound8K_test.pkl', mode),\n","              batch_size=1, shuffle=False,\n","              num_workers=args.worker_count, pin_memory=True)\n","        \n","        height_val = 85\n","        if mode == 'MLMC': \n","            height_val = 145\n","        model = CNN(height=height_val, width=41, channels=1, class_count=10, dropout = args.dropout, mode = args.mode)\n","        criterion = lambda logits, labels : nn.CrossEntropyLoss()(logits, labels)\n","        optimizer = torch.optim.Adam(model.parameters(), args.learning_rate)#, weight_decay=args.weight_decay)#, momentum =args.sgd_momentum)\n","\n","\n","        log_dir = get_summary_writer_log_dir(args)\n","        print(f\"Writing logs to {log_dir}\")\n","        summary_writer = SummaryWriter(\n","                str(log_dir),\n","                flush_secs=5\n","        )\n","        trainer = Trainer(\n","            model, train_loader, val_loader, criterion, optimizer, summary_writer, DEVICE, \n","            checkpoint_path\n","        )\n","        trainer.train(\n","            args.epochs,\n","            args.val_frequency,\n","            print_frequency=args.print_frequency,\n","            log_frequency=args.log_frequency,\n","        )\n","\n","        summary_writer.close()\n","\n","        checkpoint = torch.load(checkpoint_path)\n","        model.load_state_dict(checkpoint['model'])\n","        validation = Trainer(model, train_loader, val_loader, criterion, optimizer, summary_writer, DEVICE, \n","            checkpoint_path)\n","        dummy, scores, labels = validation.validate(100, 1, 1)\n","        scores = scores.cpu()\n","        pickle.dump(scores, open(f\"{mode}_scores.p\", \"wb\"))\n","        pickle.dump(labels, open(\"labels.p\", \"wb\"))\n","    \n","\n","class CNN(nn.Module):\n","    def __init__(self, height: int, width: int, channels: int, class_count: int, dropout: float, mode: str):\n","        super().__init__()\n","        self.input_shape = ImageShape(height=height, width=width, channels=channels)\n","        self.class_count = class_count\n","        ## Convolution layer 1\n","        self.conv1 = nn.Conv2d(\n","            in_channels=self.input_shape.channels,\n","            out_channels=32,\n","            kernel_size=(3,3),\n","            padding=(1,1),\n","            stride=(1,1),\n","        )\n","        # batch normalisation\n","        self.conv1_BN = nn.BatchNorm2d(32)\n","        self.initialise_layer(self.conv1)\n","\n","        ## Convolution layer 2\n","        self.conv2 = nn.Conv2d(\n","            in_channels=self.conv1.out_channels,\n","            out_channels=32,\n","            kernel_size=(3,3),\n","            padding=(1,1),\n","            stride=(1,1),\n","            )\n","        # dropout\n","        self.dropout2d = nn.Dropout2d(dropout)\n","        self.conv2_BN = nn.BatchNorm2d(32)\n","        self.initialise_layer(self.conv2)\n","        # pooling layer\n","        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2), padding=(1,1))\n","\n","        ## Convolution layer 3\n","        self.conv3 = nn.Conv2d(\n","            in_channels=self.conv2.out_channels,\n","            out_channels=64,\n","            kernel_size=(3,3),\n","            padding=(1,1),\n","            stride=(1,1),\n","        )\n","         \n","        self.conv3_BN = nn.BatchNorm2d(64)\n","        self.initialise_layer(self.conv3)\n","        ## Convolution layer 4\n","        self.conv4 = nn.Conv2d(\n","            in_channels=self.conv3.out_channels,\n","            out_channels=64,\n","            kernel_size=(3,3),\n","            padding=(1,1),\n","            stride=(1,1),\n","            )\n","        self.conv4_BN = nn.BatchNorm2d(64)\n","        self.initialise_layer(self.conv4)\n","\n","        ## Fully-Connected layer\n","        in_size = 15488\n","        if mode == 'MLMC':\n","            in_size = 26048\n","        self.fc1 = nn.Linear(in_size, 1024)\n","        self.fc1_BN = nn.BatchNorm1d(1024)\n","        self.dropout = nn.Dropout(dropout)\n","        self.initialise_layer(self.fc1)\n","        \n","        ## Output layer\n","        self.fc3 = nn.Linear(1024, 10)\n","        self.initialise_layer(self.fc3)\n","\n","    def forward(self, images: torch.Tensor) -> torch.Tensor:\n","        # Conv 1 --> batch norm --> relu\n","        x = F.relu(self.conv1_BN(self.conv1(images)))\n","        # Conv 2 --> batch norm --> relu --> dropout --> pooling\n","        x = self.dropout2d(F.relu(self.conv2_BN(self.conv2(x))))\n","        x = self.pool(x)\n","        # Conv 3 --> batch norm --> relu --> dropout\n","        x = self.dropout2d(F.relu(self.conv3_BN(self.conv3(x))))\n","        # Conv 4 --> batch norm --> relu --> dropout --> pooling\n","        x = self.dropout2d(F.relu(self.conv4_BN(self.conv4(x))))\n","        x = self.pool(x)\n","        # Flatten output of pooling layer\n","        x = torch.flatten(x, 1)\n","        # FC layer 1 --> batch norm --> sigmoid --> dropout\n","        x = self.dropout(torch.sigmoid(self.fc1_BN(self.fc1(x))))\n","        # Output layer\n","        x = self.fc3(x)\n","        return x\n","\n","    @staticmethod\n","    def initialise_layer(layer):\n","        if hasattr(layer, \"bias\"):\n","            nn.init.zeros_(layer.bias)\n","        if hasattr(layer, \"weight\"):\n","            nn.init.kaiming_normal_(layer.weight)\n","\n","\n","class Trainer:\n","    def __init__(\n","        self,\n","        model: nn.Module,\n","        train_loader: DataLoader,\n","        val_loader: DataLoader,\n","        criterion: nn.Module,\n","        optimizer: Optimizer,\n","        summary_writer: SummaryWriter,\n","        device: torch.device,\n","        checkpoint_path: Path,\n","    ):\n","        self.model = model.to(device)\n","        self.device = device\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.criterion = criterion\n","        self.optimizer = optimizer\n","        self.summary_writer = summary_writer\n","        self.step = 0\n","        self.checkpoint_path = checkpoint_path\n","\n","    def train(\n","        self,\n","        epochs: int,\n","        val_frequency: int,\n","        print_frequency: int = 20,\n","        log_frequency: int = 5,\n","        start_epoch: int = 0\n","    ):\n","        self.model.train()\n","        best_acc = 0\n","        for epoch in range(start_epoch, epochs):\n","            self.model.train()\n","            data_load_start_time = time.time()\n","            for batch, labels, filename in self.train_loader:\n","                batch = batch.to(self.device)\n","                labels = labels.to(self.device)\n","                data_load_end_time = time.time()\n","                # Forward pass\n","                logits = self.model.forward(batch)\n","                # Compute loss\n","                loss = self.criterion(logits, labels)\n","                # Compute the backward pass\n","                loss.backward()\n","                # Step optimizer\n","                self.optimizer.step()\n","                # Zero gradient buffers\n","                self.optimizer.zero_grad()\n","                # Compute accuracy\n","                with torch.no_grad():\n","                    preds = logits.argmax(-1)\n","                    accuracy, per_class_accuracy = compute_accuracy(labels, preds)\n","\n","                # output metrics and log files \n","                data_load_time = data_load_end_time - data_load_start_time\n","                step_time = time.time() - data_load_end_time\n","                if ((self.step + 1) % log_frequency) == 0:\n","                    self.log_metrics(epoch, accuracy, loss, data_load_time, step_time)\n","                if ((self.step + 1) % print_frequency) == 0:\n","                    self.print_metrics(epoch, accuracy, loss, data_load_time, step_time)\n","\n","                self.step += 1\n","                data_load_start_time = time.time()\n"," \n","            self.summary_writer.add_scalar(\"epoch\", epoch, self.step)\n","\n","            if ((epoch + 1) % val_frequency) == 0:\n","                # switch to validation mode\n","                best_acc, dummy, dummy1 = self.validate(best_acc, epoch, epochs) #, ~\n","                # switch back to train mode\n","                self.model.train()\n","    def print_metrics(self, epoch, accuracy, loss, data_load_time, step_time):\n","        # online print meterics \n","        epoch_step = self.step % len(self.train_loader)\n","        print(\n","                f\"epoch: [{epoch}], \"\n","                f\"step: [{epoch_step}/{len(self.train_loader)}], \"\n","                f\"batch loss: {loss:.5f}, \"\n","                f\"batch accuracy: {accuracy * 100:2.2f}, \"\n","                f\"data load time: \"\n","                f\"{data_load_time:.5f}, \"\n","                f\"step time: {step_time:.5f}\"\n","        )\n","\n","    def log_metrics(self, epoch, accuracy, loss, data_load_time, step_time):\n","        # summary writer for logs files\n","        self.summary_writer.add_scalar(\"epoch\", epoch, self.step)\n","        self.summary_writer.add_scalars(\n","                \"accuracy\",\n","                {\"train\": accuracy},\n","                self.step\n","        )\n","        self.summary_writer.add_scalars(\n","                \"loss\",\n","                {\"train\": float(loss.item())},\n","                self.step\n","        )\n","        self.summary_writer.add_scalar(\n","                \"time/data\", data_load_time, self.step\n","        )\n","        self.summary_writer.add_scalar(\n","                \"time/data\", step_time, self.step\n","        )\n","\n","    def validate(self, best_acc, epoch, epochs):\n","        '''Model validation - validates the model by computing per file accuracy. \n","\n","        Args: \n","            best_acc: (float) current best accuracy for the run\n","            epoch: (int) current epoch No. \n","            epochs: (int) total number of epochs\n","\n","        Returns: \n","            best_acc: (float) current best accuracy for the run\n","            save_scores: (tensor) contains all per file averages scores for use in TSCNN model \n","        ''' \n","        results = {\"preds\": [], \"labels\": []}\n","        total_loss = 0\n","        self.model.eval()\n","        current_filename = ''\n","        file_scores = torch.zeros([1,10])\n","        file_scores = file_scores.to(self.device)\n","        save_scores = torch.zeros([836, 10])\n","        save_scores = save_scores.to(self.device)\n","        n = 0 \n","\n","        # No need to track gradients for validation, we're not optimizing.\n","        with torch.no_grad():\n","            for batch, labels, filename in self.val_loader:\n","                # all files are in order, as soon as new filename detected -> compute prediction \n","                if current_filename != filename and current_filename != '':\n","                    # softmax for normalisation \n","                    file_scores = F.softmax(file_scores, 1)\n","                    # take the average class-wise\n","                    file_scores = torch.sum(file_scores, 0)/(file_scores.size()[0]-1)\n","                    # calc prediction \n","                    preds = file_scores.argmax(dim=-1).cpu().numpy()\n","                    results[\"preds\"].extend([preds])\n","                    results[\"labels\"].extend(list(current_label.cpu().numpy()))\n","                    # save scores for end validation scores  \n","                    save_scores[n] = file_scores\n","                    n += 1\n","                    file_scores = torch.zeros([1,10])\n","                    file_scores = file_scores.to(self.device)\n","                \n","                # calc logits \n","                batch = batch.to(self.device)\n","                labels = labels.to(self.device)\n","                logits = self.model(batch)\n","                loss = self.criterion(logits, labels)\n","                total_loss += loss.item()\n","                # concat scores while same filename \n","                file_scores = torch.cat((file_scores, logits), 0)\n","                # save filename to compare against next\n","                current_filename = filename\n","                current_label = labels\n","\n","        # compute validation accuracy \n","        accuracy, per_class_accuracy = compute_accuracy(\n","            np.array(results[\"labels\"]), np.array(results[\"preds\"])\n","        )\n","        # save model checkpoint if better average accuracy \n","        if best_acc < accuracy:\n","                self.model_checkpoint(accuracy, epoch)\n","                best_acc = accuracy\n","                \n","        average_loss = total_loss / len(self.val_loader)\n","        \n","        # summary writer statistics \n","        self.summary_writer.add_scalars(\n","                \"accuracy\",\n","                {\"test\": accuracy},\n","                self.step\n","        )\n","        self.summary_writer.add_scalars(\n","                \"loss\",\n","                {\"test\": average_loss},\n","                self.step\n","        )\n","        \n","        # output accuracy, loss and class-wise accuracy \n","        class_labels = [\"ac\", \"ch\", \"cp\", \"db\", \"dr\", \"ei\", \"gs\", \"jh\", \"si\", \"sm\"]\n","        print(f\"validation loss: {average_loss:.5f}, accuracy: {accuracy * 100:2.2f}\")\n","        for i in range(0,10):\n","            print(f\"{class_labels[i]}_acc: {per_class_accuracy[i] * 100:2.2f}\")\n","\n","        return float(best_acc), save_scores, results['labels']\n","\n","    def model_checkpoint(self, accuracy, epoch):\n","      \"\"\"Saves model checkpoint under checkpoint path at the epoch. \n","\n","      Args: \n","          accuracy: (float) current accuracy of model \n","          epoch: (int) current epoch of model \n","      \"\"\"\n","      print(f\"Saving model to {self.checkpoint_path}\")\n","      torch.save({\n","          'epoch': epoch,\n","          'model': self.model.state_dict(),\n","          'accuracy': accuracy\n","      }, self.checkpoint_path)\n","\n","\n","\n","def compute_accuracy(\n","    labels: Union[torch.Tensor, np.ndarray], preds: Union[torch.Tensor, np.ndarray]\n",") -> float:\n","    \"\"\"Computes class-wise accuracy and accuracy and ensures no division by zero. \n","\n","    Args:\n","        labels: ``(batch_size, class_count)`` tensor or array containing example labels\n","        preds: ``(batch_size, class_count)`` tensor or array containing model prediction\n","    \n","    Returns: \n","        Classwise accuracy, accuracy \n","    \"\"\"\n","    # check No. labels = No. preds\n","    assert len(labels) == len(preds)\n","    class_acc = torch.zeros(10)\n","    # computes class-wise accuracy \n","    for i in range(0,10):\n","        c = (preds[labels == i] == i).sum()\n","        d = sum(labels == i)\n","        if d != 0:\n","            class_acc[i] = c/d\n","        elif c > 0:\n","            class_acc[i] = 0\n","        else:\n","            class_acc[i] = 100\n","\n","    return float((labels == preds).sum()) / len(labels), class_acc\n","\n","\n","def get_summary_writer_log_dir(args: argparse.Namespace) -> str:\n","    \"\"\"Get a unique directory that hasn't been logged to before for use with a TB\n","    SummaryWriter.\n","\n","    Args:\n","        args: CLI Arguments\n","\n","    Returns:\n","        Subdirectory of log_dir with unique subdirectory name to prevent multiple runs\n","        from getting logged to the same TB log directory (which you can't easily\n","        untangle in TB).\n","    \"\"\"\n","    tb_log_dir_prefix = (\n","      f\"CNN_bn_\"\n","      f\"run_\"\n","      f\"mode_{args.mode}\"\n","    )\n","    i = 0\n","    while i < 1000:\n","        tb_log_dir = args.log_dir / (tb_log_dir_prefix + str(i))\n","        if not tb_log_dir.exists():\n","            return str(tb_log_dir)\n","        i += 1\n","    return str(tb_log_dir)\n","\n","\n","if __name__ == \"__main__\":\n","    main(parser.parse_args())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["LMC_accuracy: 80.7\n","ac_acc: 78.4\n","ch_acc: 93.9\n","cp_acc: 62.9\n","db_acc: 78.0\n","dr_acc: 86.7\n","ei_acc: 83.1\n","gs_acc: 94.1\n","jh_acc: 89.3\n","si_acc: 82.5\n","sm_acc: 85.7\n","MC_accuracy: 79.9\n","ac_acc: 77.6\n","ch_acc: 92.6\n","cp_acc: 67.8\n","db_acc: 89.9\n","dr_acc: 76.7\n","ei_acc: 72.8\n","gs_acc: 84.2\n","jh_acc: 100.0\n","si_acc: 96.6\n","sm_acc: 69.1\n","MLMC_accuracy: 78.6\n","ac_acc: 82.9\n","ch_acc: 100.0\n","cp_acc: 52.8\n","db_acc: 80.8\n","dr_acc: 80.2\n","ei_acc: 90.5\n","gs_acc: 93.9\n","jh_acc: 94.1\n","si_acc: 68.1\n","sm_acc: 87.2\n"],"name":"stdout"}]}]}