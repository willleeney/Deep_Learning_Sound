{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of deep_learning_project.ipynb","provenance":[{"file_id":"1vskKvorURMF78QDQfU3AGFlbFllhMeK1","timestamp":1578436701176}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"v7hi-HFFUEBD","colab_type":"code","outputId":"cfb2b18a-242b-40a0-e7f8-3f5d6fa1b540","executionInfo":{"status":"ok","timestamp":1578828490498,"user_tz":0,"elapsed":24215,"user":{"displayName":"Will Leeney","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD-9CtGsg_Lu6ZnMvRSZ00NwTBxu8ocBiKBqmrJ5G0=s64","userId":"12065771172714949840"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["### CODE TO ACCESS DRIVE ###\n","# Run\n","# Follow Link\n","# Copy Link, Paste and Enter \n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XsL7HM-rUIod","colab_type":"code","outputId":"5bdc05bf-4eae-4b82-941e-7f36ff16eb95","executionInfo":{"status":"ok","timestamp":1578828493252,"user_tz":0,"elapsed":510,"user":{"displayName":"Will Leeney","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD-9CtGsg_Lu6ZnMvRSZ00NwTBxu8ocBiKBqmrJ5G0=s64","userId":"12065771172714949840"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Change to Drive folder - might be different path\n","%cd /content/drive/My Drive/'Colab Notebooks'/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wuU50PPAU-3k","colab_type":"code","outputId":"df4e29d4-b4cb-402d-f904-70c859759755","executionInfo":{"status":"ok","timestamp":1578430960646,"user_tz":0,"elapsed":5807,"user":{"displayName":"Will Leeney","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD-9CtGsg_Lu6ZnMvRSZ00NwTBxu8ocBiKBqmrJ5G0=s64","userId":"12065771172714949840"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Check in correct folder \n","%ls"],"execution_count":0,"outputs":[{"output_type":"stream","text":["checkpoint.pkl               Lab4.ipynb    UrbanSound8K_test.pkl\n","dataset.py                   \u001b[0m\u001b[01;34mlogs\u001b[0m/         UrbanSound8K_train.pkl\n","deep_learning_project.ipynb  \u001b[01;34m__pycache__\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JO9_u3TeQYBm","colab_type":"code","outputId":"86400d6e-8507-4f2a-f644-fbad4b7a6c0e","executionInfo":{"status":"error","timestamp":1578436659946,"user_tz":0,"elapsed":6900,"user":{"displayName":"Will Leeney","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mD-9CtGsg_Lu6ZnMvRSZ00NwTBxu8ocBiKBqmrJ5G0=s64","userId":"12065771172714949840"}},"colab":{"base_uri":"https://localhost:8080/","height":358}},"source":["## Libraries\n","import time\n","from multiprocessing import cpu_count\n","from typing import Union, NamedTuple\n","\n","import torch\n","import torch.backends.cudnn\n","import numpy as np\n","from torch import nn, optim\n","from torch.nn import functional as F\n","import torchvision.datasets\n","from torch.optim.optimizer import Optimizer\n","from torch.utils.data import DataLoader\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision import transforms\n","\n","import argparse\n","import os\n","from pathlib import Path\n","\n","from torch.utils import data\n","from dataset import UrbanSound8KDataset\n","import random\n","\n","torch.backends.cudnn.benchmark = True\n","parser = argparse.ArgumentParser(\n","                        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n","                        )\n","## Arguments\n","default_dataset_dir = Path.home() / \".cache\" / \"torch\" / \"datasets\"\n","parser.add_argument(\"--log-dir\", default=Path(\"logs\"), type=Path)\n","parser.add_argument(\"--dataset-root\", default=default_dataset_dir)\n","parser.add_argument(\"--learning_rate\",default = 1e-3, type=float, help=\"Learning rate\")\n","parser.add_argument(\"--sgd_momentum\",default =  0.9, type=float)\n","parser.add_argument(\"--dropout\", default = 0.5, type = float)\n","parser.add_argument(\"--mode\", default = 'LMC', type = str)\n","parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n","parser.add_argument(\n","    \"--batch-size\",\n","    default=32,\n","    type=int,\n","    help=\"Number of images within each mini-batch\",\n",")\n","parser.add_argument(\n","    \"--epochs\",\n","    default=31,\n","    type=int,\n","    help=\"Number of epochs (passes through the entire dataset) to train for\",\n",")\n","parser.add_argument(\n","    \"--val-frequency\",\n","    default=1,\n","    type=int,\n","    help=\"How frequently to test the model on the validation set in number of epochs\",\n","    )\n","parser.add_argument(\n","    \"--log-frequency\",\n","    default=10,\n","    type=int,\n","    help=\"How frequently to save logs to tensorboard in number of steps\",\n",")\n","parser.add_argument(\n","    \"--print-frequency\",\n","    default=100,\n","    type=int,\n","    help=\"How frequently to print progress to the command line in number of steps\",\n",")\n","parser.add_argument(\n","    \"-j\",\n","    \"--worker-count\",\n","    default=cpu_count(),\n","    type=int,\n","    help=\"Number of worker processes used to load data.\",\n",")\n","parser.add_argument(\n","    \"--checkpoint-path\",\n","    default=Path(\"checkpoint.pkl\"),\n","    type=Path,\n","    help=\"Provide a file to store checkpoints of the model parameters during training.\"\n",")\n","parser.add_argument(\n","    \"--checkpoint-frequency\",\n","    type=int, default=5,\n","    help=\"Save a checkpoint every N epochs\"\n",")\n","parser.add_argument(\n","    \"--weight_decay\",\n","    default=1e-5,\n","    type=float,\n","    help=\"Weight decay: parameter related to L-2 regularisation.\",\n",")\n","\n","class ImageShape(NamedTuple):\n","    height: int\n","    width: int\n","    channels: int\n","\n","if torch.cuda.is_available():\n","    DEVICE = torch.device(\"cuda\")\n","else:\n","    DEVICE = torch.device(\"cpu\")\n","\n","def main(args):\n","    args.dataset_root.mkdir(parents=True, exist_ok=True)\n","    ## Choose which features to learn ( this can be an argument/ choose which net)\n","    mode = args.mode\n","    ## load data\n","    train_loader = torch.utils.data.DataLoader(\n","        UrbanSound8KDataset('UrbanSound8K_train.pkl', mode),\n","          batch_size=args.batch_size, shuffle=True,\n","          num_workers=args.worker_count, pin_memory=True\n","          )\n","\n","    val_loader = torch.utils.data.DataLoader(\n","        UrbanSound8KDataset('UrbanSound8K_test.pkl', mode),\n","          batch_size=1, shuffle=False,\n","          num_workers=args.worker_count, pin_memory=True)\n","    height_val = 85\n","    if mode == 'MLMC': \n","        height_val = 145\n","    model = CNN(height=height_val, width=41, channels=1, class_count=10, dropout = args.dropout, mode = args.mode)\n","    criterion = lambda logits, labels : nn.CrossEntropyLoss()(logits, labels)\n","    optimizer = torch.optim.Adam(model.parameters(), args.learning_rate, weight_decay=args.weight_decay)#, momentum =args.sgd_momentum)\n","\n","\n","    log_dir = get_summary_writer_log_dir(args)\n","    print(f\"Writing logs to {log_dir}\")\n","    summary_writer = SummaryWriter(\n","            str(log_dir),\n","            flush_secs=5\n","    )\n","    trainer = Trainer(\n","        model, train_loader, val_loader, criterion, optimizer, summary_writer, DEVICE, \n","        args.checkpoint_path, checkpoint_frequency = args.checkpoint_frequency\n","    )\n","\n","    trainer.train(\n","        args.epochs,\n","        args.val_frequency,\n","        print_frequency=args.print_frequency,\n","        log_frequency=args.log_frequency,\n","    )\n","\n","    summary_writer.close()\n","\n","class CNN(nn.Module):\n","    def __init__(self, height: int, width: int, channels: int, class_count: int, dropout: float, mode: str):\n","        super().__init__()\n","        self.input_shape = ImageShape(height=height, width=width, channels=channels)\n","        self.class_count = class_count\n","        ## Convolution layer 1\n","        self.conv1 = nn.Conv2d(\n","            in_channels=self.input_shape.channels,\n","            out_channels=32,\n","            kernel_size=(4,4),\n","            padding=(2,2),\n","            stride=(2,1),\n","        )\n","        # batch normalisation\n","        self.conv1_BN = nn.BatchNorm2d(32)\n","        self.initialise_layer(self.conv1)\n","\n","        ## Convolution layer 2\n","        self.conv2 = nn.Conv2d(\n","            in_channels=self.conv1.out_channels,\n","            out_channels=64,\n","            kernel_size=(4,4),\n","            padding=(2,2),\n","            stride=(2,1),\n","            )\n","        # dropout\n","        self.dropout2d = nn.Dropout2d(dropout)\n","        self.conv2_BN = nn.BatchNorm2d(64)\n","        self.initialise_layer(self.conv2)\n","        # pooling layer\n","        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2), padding=(1,1))\n","\n","        ## Convolution layer 3\n","        self.conv3 = nn.Conv2d(\n","            in_channels=self.conv2.out_channels,\n","            out_channels=128,\n","            kernel_size=(3,3),\n","            padding=(1,1),\n","            stride=(1,1),\n","        )\n","         \n","        self.conv3_BN = nn.BatchNorm2d(128)\n","        self.initialise_layer(self.conv3)\n","        ## Convolution layer 4\n","        self.conv4 = nn.Conv2d(\n","            in_channels=self.conv3.out_channels,\n","            out_channels=128,\n","            kernel_size=(3,3),\n","            padding=(1,1),\n","            stride=(1,1),\n","            )\n","        self.conv4_BN = nn.BatchNorm2d(128)\n","        self.initialise_layer(self.conv4)\n","\n","        ## Fully-Connected layer\n","        in_size = 10752\n","        if mode == 'MLMC':\n","            in_size = 9216\n","        self.fc1 = nn.Linear(in_size, 1024)\n","        self.fc1_BN = nn.BatchNorm1d(1024)\n","        self.initialise_layer(self.fc1)\n","        self.dropout = nn.Dropout(dropout)\n","        ## Second Fully-Connected layer\n","       # self.fc2 = nn.Linear(8192, 1024)\n","        #self.fc2_BN = nn.BatchNorm1d(1024)\n","        #self.initialise_layer(self.fc2)\n","\n","        ## Output layer\n","        self.fc3 = nn.Linear(1024, 10)\n","        self.initialise_layer(self.fc3)\n","\n","    def forward(self, images: torch.Tensor) -> torch.Tensor:\n","        # Conv 1 --> batch norm --> relu\n","        x = F.relu(self.conv1_BN(self.conv1(images)))\n","        #print(x.size())\n","        # Conv 2 --> batch norm --> relu --> dropout --> pooling\n","        x = self.dropout2d(F.relu(self.conv2_BN(self.conv2(x))))\n","        #print(x.size())\n","        x = self.pool(x)\n","        #print(x.size())\n","        # Conv 3 --> batch norm --> relu --> dropout\n","        x = self.dropout2d(F.relu(self.conv3_BN(self.conv3(x))))\n","        #print(x.size())\n","        # Conv 4 --> batch norm --> relu --> dropout --> pooling\n","        x = self.dropout2d(F.relu(self.conv4_BN(self.conv4(x))))\n","        #print(x.size())\n","        x = self.pool(x)\n","        #print(x.size())\n","        # Flatten output of pooling layer\n","        x = torch.flatten(x, 1)\n","        # FC layer 1 --> batch norm --> sigmoid\n","        x = self.dropout(torch.sigmoid(self.fc1_BN(self.fc1(x))))\n","        #x = torch.sigmoid(self.fc1(x))\n","        # FC layer 2 -- sigmoid\n","        #x = torch.sigmoid(self.fc2_BN(self.fc2(x)))\n","        # Output layer\n","        x = self.fc3(x)\n","        #x = F.log_softmax(self.fc3(x), 1)\n","        return x\n","\n","    @staticmethod\n","    def initialise_layer(layer):\n","        if hasattr(layer, \"bias\"):\n","            nn.init.zeros_(layer.bias)\n","        if hasattr(layer, \"weight\"):\n","            nn.init.kaiming_normal_(layer.weight)\n","\n","\n","class Trainer:\n","    def __init__(\n","        self,\n","        model: nn.Module,\n","        train_loader: DataLoader,\n","        val_loader: DataLoader,\n","        criterion: nn.Module,\n","        optimizer: Optimizer,\n","        summary_writer: SummaryWriter,\n","        device: torch.device,\n","        checkpoint_path: Path,\n","        checkpoint_frequency: int = 5\n","    ):\n","        self.model = model.to(device)\n","        self.device = device\n","        self.train_loader = train_loader\n","        self.val_loader = val_loader\n","        self.criterion = criterion\n","        self.optimizer = optimizer\n","        self.summary_writer = summary_writer\n","        self.step = 0\n","        self.checkpoint_path = checkpoint_path\n","        self.checkpoint_frequency = checkpoint_frequency\n","\n","    def train(\n","        self,\n","        epochs: int,\n","        val_frequency: int,\n","        print_frequency: int = 20,\n","        log_frequency: int = 5,\n","        start_epoch: int = 0\n","    ):\n","        self.model.train()\n","        gamma = 0.55\n","        for epoch in range(start_epoch, epochs):\n","            self.model.train()\n","            data_load_start_time = time.time()\n","            for batch, labels, filename in self.train_loader:\n","                batch = batch.to(self.device)\n","                labels = labels.to(self.device)\n","                data_load_end_time = time.time()\n","                \n","\n","                ##### Adding guassian noise ##### \n","               # if epoch < 5: \n","                    #Nu = random.randint(0, 1)\n","                    #if Nu == 0: \n","                    #  Nu = 0.01\n","                    #elif Nu == 1: \n","                    #  Nu = 0.5\n","                  #  Nu = 1\n","                 #   noise_var = (Nu/(1+self.step)**gamma)**0.5\n","                #    noise_torch = torch.randn(batch.size())\n","                   # noise_torch = noise_torch.to(self.device)\n","                   # batch += noise_torch\n","\n","                # Forward pass\n","                logits = self.model.forward(batch)\n","                #break\n","                # Compute loss\n","                loss = self.criterion(logits, labels)\n","                # Compute the backward pass\n","                loss.backward()\n","                # Step optimizer\n","                self.optimizer.step()\n","                # Zero gradient buffers\n","                self.optimizer.zero_grad()\n","                # Compute accurracy\n","                with torch.no_grad():\n","                    preds = logits.argmax(-1)\n","                    accuracy, per_class_accuracy = compute_accuracy(labels, preds)\n","\n","                data_load_time = data_load_end_time - data_load_start_time\n","                step_time = time.time() - data_load_end_time\n","                if ((self.step + 1) % log_frequency) == 0:\n","                    self.log_metrics(epoch, accuracy, loss, data_load_time, step_time)\n","                if ((self.step + 1) % print_frequency) == 0:\n","                    self.print_metrics(epoch, accuracy, loss, data_load_time, step_time)\n","\n","                self.step += 1\n","                data_load_start_time = time.time()\n","            \n","            self.model_checkpoint(accuracy, epoch, epochs)\n","\n","            self.summary_writer.add_scalar(\"epoch\", epoch, self.step)\n","            if ((epoch + 1) % val_frequency) == 0:\n","                self.validate()\n","                # self.validate() will put the model in validation mode,\n","                # so we have to switch back to train mode afterwards\n","                self.model.train()\n","\n","         # end validation code can go here\n","    def print_metrics(self, epoch, accuracy, loss, data_load_time, step_time):\n","        epoch_step = self.step % len(self.train_loader)\n","        print(\n","                f\"epoch: [{epoch}], \"\n","                f\"step: [{epoch_step}/{len(self.train_loader)}], \"\n","                f\"batch loss: {loss:.5f}, \"\n","                f\"batch accuracy: {accuracy * 100:2.2f}, \"\n","                f\"data load time: \"\n","                f\"{data_load_time:.5f}, \"\n","                f\"step time: {step_time:.5f}\"\n","        )\n","\n","    def log_metrics(self, epoch, accuracy, loss, data_load_time, step_time):\n","        self.summary_writer.add_scalar(\"epoch\", epoch, self.step)\n","        self.summary_writer.add_scalars(\n","                \"accuracy\",\n","                {\"train\": accuracy},\n","                self.step\n","        )\n","        self.summary_writer.add_scalars(\n","                \"loss\",\n","                {\"train\": float(loss.item())},\n","                self.step\n","        )\n","        self.summary_writer.add_scalar(\n","                \"time/data\", data_load_time, self.step\n","        )\n","        self.summary_writer.add_scalar(\n","                \"time/data\", step_time, self.step\n","        )\n","\n","    def validate(self):\n","        results = {\"preds\": [], \"labels\": []}\n","        total_loss = 0\n","        self.model.eval()\n","        current_filename = ''\n","        file_scores = torch.zeros([1,10])\n","        file_scores = file_scores.to(self.device)\n","\n","        # No need to track gradients for validation, we're not optimizing.\n","        with torch.no_grad():\n","            for batch, labels, filename in self.val_loader:\n","                if current_filename != filename and current_filename != '':\n","                    file_scores = F.softmax(file_scores, 1)\n","                    file_scores = torch.sum(file_scores, 0)/(file_scores.size()[0]-1)\n","                    preds = file_scores.argmax(dim=-1).cpu().numpy()\n","                    results[\"preds\"].extend([preds])\n","                    results[\"labels\"].extend(list(current_label.cpu().numpy()))\n","                    file_scores = torch.zeros([1,10])\n","                    file_scores = file_scores.to(self.device)\n","                    #print(current_filename)\n","                    \n","\n","                batch = batch.to(self.device)\n","                labels = labels.to(self.device)\n","                logits = self.model(batch)\n","                loss = self.criterion(logits, labels)\n","                total_loss += loss.item()\n","                file_scores = torch.cat((file_scores, logits), 0)\n","                current_filename = filename\n","                current_label = labels\n","\n","\n","        accuracy, per_class_accuracy = compute_accuracy(\n","            np.array(results[\"labels\"]), np.array(results[\"preds\"])\n","        )\n","        average_loss = total_loss / len(self.val_loader)\n","\n","        self.summary_writer.add_scalars(\n","                \"accuracy\",\n","                {\"test\": accuracy},\n","                self.step\n","        )\n","        self.summary_writer.add_scalars(\n","                \"loss\",\n","                {\"test\": average_loss},\n","                self.step\n","        )\n","        class_labels = [\"ac\", \"ch\", \"cp\", \"db\", \"dr\", \"ei\", \"gs\", \"jh\", \"si\", \"sm\"]\n","        print(f\"validation loss: {average_loss:.5f}, accuracy: {accuracy * 100:2.2f}\")\n","        for i in range(0,10):\n","            print(f\"{class_labels[i]}_acc: {per_class_accuracy[i] * 100:2.2f}\")\n","\n","    def model_checkpoint(self, accuracy, epoch, epochs):\n","        if (epoch + 1) % self.checkpoint_frequency == 0 or (epoch + 1) == epochs:\n","            print(f\"Saving model to {self.checkpoint_path}\")\n","            torch.save({\n","                'epoch': epoch,\n","                'model': self.model.state_dict(),\n","                'accuracy': accuracy\n","            }, self.checkpoint_path)\n","\n","\n","\n","def compute_accuracy(\n","    labels: Union[torch.Tensor, np.ndarray], preds: Union[torch.Tensor, np.ndarray]\n",") -> float:\n","    \"\"\"\n","    Args:\n","        labels: ``(batch_size, class_count)`` tensor or array containing example labels\n","        preds: ``(batch_size, class_count)`` tensor or array containing model prediction\n","    \"\"\"\n","    assert len(labels) == len(preds)\n","    class_acc = torch.zeros(10)\n","    for i in range(0,10):\n","        c = (preds[labels == i] == i).sum()\n","        d = sum(labels == i)\n","        if d != 0:\n","            class_acc[i] = c/d\n","        elif c > 0:\n","            class_acc[i] = 0\n","        else:\n","            class_acc[i] = 100\n","\n","    return float((labels == preds).sum()) / len(labels), class_acc\n","\n","\n","def get_summary_writer_log_dir(args: argparse.Namespace) -> str:\n","    \"\"\"Get a unique directory that hasn't been logged to before for use with a TB\n","    SummaryWriter.\n","\n","    Args:\n","        args: CLI Arguments\n","\n","    Returns:\n","        Subdirectory of log_dir with unique subdirectory name to prevent multiple runs\n","        from getting logged to the same TB log directory (which you can't easily\n","        untangle in TB).\n","    \"\"\"\n","    tb_log_dir_prefix = (\n","      f\"the_base_line\"\n","      f\"CNN_bn_\"\n","      #f\"dropout={args.dropout}_\"\n","     # f\"bs={args.batch_size}_\"\n","      #f\"lr={args.learning_rate}_\"\n","      #f\"momentum={args.sgd_momentum}_\" +\n","      f\"run_\"\n","    )\n","    i = 0\n","    while i < 1000:\n","        tb_log_dir = args.log_dir / (tb_log_dir_prefix + str(i))\n","        if not tb_log_dir.exists():\n","            return str(tb_log_dir)\n","        i += 1\n","    return str(tb_log_dir)\n","\n","\n","if __name__ == \"__main__\":\n","    main(parser.parse_args())"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Writing logs to logs/the_base_lineCNN_bn_run_145\n"],"name":"stdout"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-672dda45cb7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-9-672dda45cb7c>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_frequency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mprint_frequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_frequency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mlog_frequency\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_frequency\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     )\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-672dda45cb7c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, val_frequency, print_frequency, log_frequency, start_epoch)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m                 \u001b[0;31m#break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-672dda45cb7c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, images)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# FC layer 1 --> batch norm --> sigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1_BN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;31m#x = torch.sigmoid(self.fc1(x))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# FC layer 2 -- sigmoid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1371\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [32 x 10752], m2: [18432 x 1024] at /pytorch/aten/src/THC/generic/THCTensorMathBlas.cu:290"]}]}]}